{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20387f0a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Research Question 2: Which mechanical taxonomy is a better predictor of subdomains \n",
    "\n",
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1be49b83",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n",
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import pymc as pm\n",
    "\n",
    "\n",
    "from scipy.stats import shapiro, anderson, jarque_bera, spearmanr, probplot\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_curve, average_precision_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from stargazer.stargazer import Stargazer\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482c96b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4beadbfa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cat_17 = pd.read_csv(f'data/2017/categories_2017.csv', index_col='Unnamed: 0', encoding='utf-8') \n",
    "mech_17 = pd.read_csv(f'data/2017/mechanics_2017.csv', index_col='Unnamed: 0', encoding='utf-8')\n",
    "sub_17 = pd.read_csv(f'data/2017/subdomains_2017.csv')\n",
    "rank_id_17 = pd.read_csv('data/2017/rank_id.csv')\n",
    "\n",
    "cat_23 = pd.read_csv(f'data/2023/categories_2023.csv', index_col='Unnamed: 0', encoding='utf-8') \n",
    "mech_23 = pd.read_csv(f'data/2023/mechanics_2023.csv', index_col='Unnamed: 0', encoding='utf-8')\n",
    "sub_23 = pd.read_csv(f'data/2023/subdomains_2023.csv')\n",
    "rank_id_23 = pd.read_csv('data/2023/rank_id.csv')\n",
    "\n",
    "df_list = [cat_17, mech_17, cat_23, mech_23]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede096c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building Ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1f6cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef0ed7e6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ddc5d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_forest(df):\n",
    "    X = df.drop(columns=['rank', 'percentile', 'game_id'])\n",
    "    y = df[:]['percentile']\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state = 54)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=54)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Model Accuracy\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "919fd44b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_percentile_column(df, rank_id):\n",
    "    df = rank_id.join(df.set_index('game_id'), on='game_id', rsuffix='_mech')\n",
    "    df['percentile'] = pd.qcut(df['rank'], q = 10, labels=False)\n",
    "    df['percentile'] = df['percentile'] + 1\n",
    "\n",
    "    percentile_col = df.columns[-1]\n",
    "    last_column = df.pop(percentile_col)\n",
    "    df.insert(1, percentile_col, last_column)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106b4a5f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be431bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printed df:    rank  percentile  geek_rating  game_id  Abstract Strategy  \\\n",
      "0     1           1      8.48904   161936                  0   \n",
      "1     2           1      8.30744   182028                  0   \n",
      "2     3           1      8.22021    12333                  0   \n",
      "3     4           1      8.15458   120677                  0   \n",
      "4     5           1      8.15151   174430                  0   \n",
      "\n",
      "   Action / Dexterity  Adventure  Age of Reason  American Civil War  \\\n",
      "0                   0          0              0                   0   \n",
      "1                   0          0              0                   0   \n",
      "2                   0          0              0                   0   \n",
      "3                   0          0              0                   0   \n",
      "4                   0          1              0                   0   \n",
      "\n",
      "   American Indian Wars  ...  Transportation  Travel  Trivia  \\\n",
      "0                     0  ...               0       0       0   \n",
      "1                     0  ...               0       0       0   \n",
      "2                     0  ...               0       0       0   \n",
      "3                     0  ...               0       0       0   \n",
      "4                     0  ...               0       0       0   \n",
      "\n",
      "   Video Game Theme  Vietnam War  Wargame  Word Game  World War I  \\\n",
      "0                 0            0        0          0            0   \n",
      "1                 0            0        0          0            0   \n",
      "2                 0            0        1          0            0   \n",
      "3                 0            0        0          0            0   \n",
      "4                 0            0        0          0            0   \n",
      "\n",
      "   World War II  Zombies  \n",
      "0             0        0  \n",
      "1             0        0  \n",
      "2             0        0  \n",
      "3             0        0  \n",
      "4             0        0  \n",
      "\n",
      "[5 rows x 87 columns]\n",
      "printed df:    rank  percentile  geek_rating  game_id  Acting  \\\n",
      "0     1           1      8.48904   161936       0   \n",
      "1     2           1      8.30744   182028       0   \n",
      "2     3           1      8.22021    12333       0   \n",
      "3     4           1      8.15458   120677       0   \n",
      "4     5           1      8.15151   174430       0   \n",
      "\n",
      "   Action / Movement Programming  Action Point Allowance System  \\\n",
      "0                              0                              1   \n",
      "1                              0                              1   \n",
      "2                              0                              0   \n",
      "3                              0                              0   \n",
      "4                              1                              0   \n",
      "\n",
      "   Area Control / Area Influence  Area Enclosure  Area Movement  ...  \\\n",
      "0                              0               0              0  ...   \n",
      "1                              0               0              0  ...   \n",
      "2                              1               0              0  ...   \n",
      "3                              0               0              0  ...   \n",
      "4                              0               0              0  ...   \n",
      "\n",
      "   Storytelling  Take That  Tile Placement  Time Track  Trading  Trick-taking  \\\n",
      "0             0          0               0           0        1             0   \n",
      "1             0          0               0           0        0             0   \n",
      "2             0          0               0           0        0             0   \n",
      "3             0          0               0           0        0             0   \n",
      "4             1          0               0           0        0             0   \n",
      "\n",
      "   Variable Phase Order  Variable Player Powers  Voting  Worker Placement  \n",
      "0                     0                       1       0                 0  \n",
      "1                     0                       0       0                 0  \n",
      "2                     0                       0       0                 0  \n",
      "3                     1                       1       0                 0  \n",
      "4                     0                       1       0                 0  \n",
      "\n",
      "[5 rows x 55 columns]\n",
      "printed df:    rank  percentile  geek_rating  game_id  Abstract Strategy  \\\n",
      "0     1           1      8.42343   224517                  0   \n",
      "1     2           1      8.38948   161936                  0   \n",
      "2     3           1      8.38731   174430                  0   \n",
      "3     4           1      8.30241   342942                  0   \n",
      "4     5           1      8.24265   233078                  0   \n",
      "\n",
      "   Action / Dexterity  Adventure  Age of Reason  American Civil War  \\\n",
      "0                   0          0              0                   0   \n",
      "1                   0          0              0                   0   \n",
      "2                   0          1              0                   0   \n",
      "3                   0          0              0                   0   \n",
      "4                   0          0              0                   0   \n",
      "\n",
      "   American Indian Wars  ...  Transportation  Travel  Trivia  \\\n",
      "0                     0  ...               1       0       0   \n",
      "1                     0  ...               0       0       0   \n",
      "2                     0  ...               0       0       0   \n",
      "3                     0  ...               0       0       0   \n",
      "4                     0  ...               0       0       0   \n",
      "\n",
      "   Video Game Theme  Vietnam War  Wargame  Word Game  World War I  \\\n",
      "0                 0            0        0          0            0   \n",
      "1                 0            0        0          0            0   \n",
      "2                 0            0        0          0            0   \n",
      "3                 0            0        0          0            0   \n",
      "4                 0            0        1          0            0   \n",
      "\n",
      "   World War II  Zombies  \n",
      "0             0        0  \n",
      "1             0        0  \n",
      "2             0        0  \n",
      "3             0        0  \n",
      "4             0        0  \n",
      "\n",
      "[5 rows x 87 columns]\n",
      "printed df:    rank  percentile  geek_rating  game_id  Acting  Action Drafting  \\\n",
      "0     1           1      8.42343   224517       0                0   \n",
      "1     2           1      8.38948   161936       0                0   \n",
      "2     3           1      8.38731   174430       0                0   \n",
      "3     4           1      8.30241   342942       0                0   \n",
      "4     5           1      8.24265   233078       0                1   \n",
      "\n",
      "   Action Points  Action Queue  Action Retrieval  Action Timer  ...  \\\n",
      "0              0             0                 0             0  ...   \n",
      "1              1             0                 0             0  ...   \n",
      "2              0             1                 1             0  ...   \n",
      "3              0             0                 0             0  ...   \n",
      "4              0             0                 0             0  ...   \n",
      "\n",
      "   Turn Order: Time Track  Variable Phase Order  Variable Player Powers  \\\n",
      "0                       0                     0                       0   \n",
      "1                       0                     0                       1   \n",
      "2                       0                     0                       1   \n",
      "3                       0                     0                       1   \n",
      "4                       0                     1                       1   \n",
      "\n",
      "   Variable Set-up  Victory Points as a Resource  Voting  Worker Placement  \\\n",
      "0                1                             0       0                 0   \n",
      "1                0                             0       0                 0   \n",
      "2                0                             0       0                 0   \n",
      "3                1                             0       0                 0   \n",
      "4                1                             0       1                 0   \n",
      "\n",
      "   Worker Placement with Dice Workers  \\\n",
      "0                                   0   \n",
      "1                                   0   \n",
      "2                                   0   \n",
      "3                                   0   \n",
      "4                                   0   \n",
      "\n",
      "   Worker Placement, Different Worker Types  Zone of Control  \n",
      "0                                         0                0  \n",
      "1                                         0                0  \n",
      "2                                         0                0  \n",
      "3                                         0                0  \n",
      "4                                         0                0  \n",
      "\n",
      "[5 rows x 192 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhous\\AppData\\Local\\Temp\\ipykernel_14144\\230298276.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['percentile'] = pd.qcut(df['rank'], q = 10, labels=False)\n",
      "C:\\Users\\mhous\\AppData\\Local\\Temp\\ipykernel_14144\\230298276.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(1, percentile_col, last_column)\n"
     ]
    }
   ],
   "source": [
    "# adding percentiles to dataframes\n",
    "for i in range(len(df_list)):\n",
    "    if 'percentile' not in df_list[i].columns:\n",
    "        if i < 2:\n",
    "            df_list[i] = add_percentile_column(df_list[i], rank_id_17)\n",
    "        else:\n",
    "            df_list[i] = add_percentile_column(df_list[i], rank_id_23)\n",
    "    else:\n",
    "        pass\n",
    "for i in range(len(df_list)):\n",
    "    print(f'printed df: {df_list[i].head()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04b0d373",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_17 = pd.merge(mech_17, sub_17, on='game_id')\n",
    "df_23 = pd.merge(mech_23, sub_23, on='game_id')\n",
    "df_list = [df_17, df_23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2596aac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier for 2017:\n",
      "Accuracy: 0.3\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    Abstract Games       0.30      0.72      0.43        76\n",
      "  Children's Games       0.16      0.72      0.27        32\n",
      "Customizable Games       0.18      0.55      0.27        33\n",
      "      Family Games       0.46      0.77      0.58       254\n",
      "       Party Games       0.34      0.73      0.46        81\n",
      "    Strategy Games       0.58      0.74      0.65       303\n",
      "    Thematic Games       0.43      0.66      0.52       163\n",
      "          Wargames       0.74      0.82      0.78       194\n",
      "\n",
      "         micro avg       0.45      0.74      0.56      1136\n",
      "         macro avg       0.40      0.71      0.49      1136\n",
      "      weighted avg       0.50      0.74      0.59      1136\n",
      "       samples avg       0.54      0.72      0.59      1136\n",
      "\n",
      "Metrics for Abstract Games Confusion Matrix \n",
      "\tSensitivity: 0.72 \n",
      "\tSpecificity: 0.86 \n",
      "\tPrecision: 0.30 \n",
      "\tNegative Predictive Value: 0.97 \n",
      "\tAccuracy: 0.85\n",
      "Metrics for Children's Games Confusion Matrix \n",
      "\tSensitivity: 0.72 \n",
      "\tSpecificity: 0.88 \n",
      "\tPrecision: 0.16 \n",
      "\tNegative Predictive Value: 0.99 \n",
      "\tAccuracy: 0.87\n",
      "Metrics for Customizable Games Confusion Matrix \n",
      "\tSensitivity: 0.55 \n",
      "\tSpecificity: 0.91 \n",
      "\tPrecision: 0.18 \n",
      "\tNegative Predictive Value: 0.98 \n",
      "\tAccuracy: 0.90\n",
      "Metrics for Family Games Confusion Matrix \n",
      "\tSensitivity: 0.77 \n",
      "\tSpecificity: 0.69 \n",
      "\tPrecision: 0.46 \n",
      "\tNegative Predictive Value: 0.90 \n",
      "\tAccuracy: 0.71\n",
      "Metrics for Party Games Confusion Matrix \n",
      "\tSensitivity: 0.73 \n",
      "\tSpecificity: 0.87 \n",
      "\tPrecision: 0.34 \n",
      "\tNegative Predictive Value: 0.97 \n",
      "\tAccuracy: 0.86\n",
      "Metrics for Strategy Games Confusion Matrix \n",
      "\tSensitivity: 0.74 \n",
      "\tSpecificity: 0.77 \n",
      "\tPrecision: 0.58 \n",
      "\tNegative Predictive Value: 0.87 \n",
      "\tAccuracy: 0.76\n",
      "Metrics for Thematic Games Confusion Matrix \n",
      "\tSensitivity: 0.66 \n",
      "\tSpecificity: 0.83 \n",
      "\tPrecision: 0.43 \n",
      "\tNegative Predictive Value: 0.93 \n",
      "\tAccuracy: 0.80\n",
      "Metrics for Wargames Confusion Matrix \n",
      "\tSensitivity: 0.82 \n",
      "\tSpecificity: 0.93 \n",
      "\tPrecision: 0.74 \n",
      "\tNegative Predictive Value: 0.96 \n",
      "\tAccuracy: 0.91\n",
      "Random Forest Classifier for 2023:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhous\\.conda\\envs\\IS_407\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mhous\\.conda\\envs\\IS_407\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5075\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "    Abstract Games       0.47      0.56      0.51        16\n",
      "  Children's Games       0.17      0.14      0.15         7\n",
      "Customizable Games       0.55      0.35      0.43        17\n",
      "      Family Games       0.72      0.58      0.64       128\n",
      "       Party Games       0.75      0.60      0.67        30\n",
      "    Strategy Games       0.77      0.80      0.78       179\n",
      "    Thematic Games       0.85      0.67      0.75        86\n",
      "          Wargames       0.82      0.71      0.76        38\n",
      "\n",
      "         micro avg       0.75      0.67      0.71       501\n",
      "         macro avg       0.64      0.55      0.59       501\n",
      "      weighted avg       0.75      0.67      0.70       501\n",
      "       samples avg       0.73      0.71      0.70       501\n",
      "\n",
      "Metrics for Abstract Games Confusion Matrix \n",
      "\tSensitivity: 0.56 \n",
      "\tSpecificity: 0.97 \n",
      "\tPrecision: 0.47 \n",
      "\tNegative Predictive Value: 0.98 \n",
      "\tAccuracy: 0.96\n",
      "Metrics for Children's Games Confusion Matrix \n",
      "\tSensitivity: 0.14 \n",
      "\tSpecificity: 0.99 \n",
      "\tPrecision: 0.17 \n",
      "\tNegative Predictive Value: 0.98 \n",
      "\tAccuracy: 0.97\n",
      "Metrics for Customizable Games Confusion Matrix \n",
      "\tSensitivity: 0.35 \n",
      "\tSpecificity: 0.99 \n",
      "\tPrecision: 0.55 \n",
      "\tNegative Predictive Value: 0.97 \n",
      "\tAccuracy: 0.96\n",
      "Metrics for Family Games Confusion Matrix \n",
      "\tSensitivity: 0.58 \n",
      "\tSpecificity: 0.89 \n",
      "\tPrecision: 0.72 \n",
      "\tNegative Predictive Value: 0.82 \n",
      "\tAccuracy: 0.79\n",
      "Metrics for Party Games Confusion Matrix \n",
      "\tSensitivity: 0.60 \n",
      "\tSpecificity: 0.98 \n",
      "\tPrecision: 0.75 \n",
      "\tNegative Predictive Value: 0.97 \n",
      "\tAccuracy: 0.95\n",
      "Metrics for Strategy Games Confusion Matrix \n",
      "\tSensitivity: 0.80 \n",
      "\tSpecificity: 0.81 \n",
      "\tPrecision: 0.77 \n",
      "\tNegative Predictive Value: 0.83 \n",
      "\tAccuracy: 0.80\n",
      "Metrics for Thematic Games Confusion Matrix \n",
      "\tSensitivity: 0.67 \n",
      "\tSpecificity: 0.97 \n",
      "\tPrecision: 0.85 \n",
      "\tNegative Predictive Value: 0.92 \n",
      "\tAccuracy: 0.91\n",
      "Metrics for Wargames Confusion Matrix \n",
      "\tSensitivity: 0.71 \n",
      "\tSpecificity: 0.98 \n",
      "\tPrecision: 0.82 \n",
      "\tNegative Predictive Value: 0.97 \n",
      "\tAccuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhous\\.conda\\envs\\IS_407\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mhous\\.conda\\envs\\IS_407\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for df in df_list:\n",
    "    year = 2017 if df.equals(df_17) else 2023\n",
    "    print(f'Random Forest Classifier for {year}:')\n",
    "    subdomains = ['Abstract Games', 'Children\\'s Games', 'Customizable Games', 'Family Games', 'Party Games', 'Strategy Games', 'Thematic Games', 'Wargames']\n",
    "\n",
    "    X = df.drop(columns=['game_id', 'Abstract Games', 'Children\\'s Games', 'Customizable Games', 'Family Games', 'Party Games', 'Strategy Games', 'Thematic Games', 'Wargames'])\n",
    "    y = df[subdomains]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=54)\n",
    "\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [500],\n",
    "        'max_depth': [None, 5, 10],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "\n",
    "\n",
    "    clf = RandomForestClassifier(class_weight='balanced', random_state = 42)\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    best_clf = grid_search.best_estimator_\n",
    "    multi_clf = MultiOutputClassifier(best_clf, n_jobs=-1)\n",
    "\n",
    "    multi_clf.fit(X_train, y_train)\n",
    "    y_pred = multi_clf.predict(X_test)\n",
    "\n",
    "    # Model Accuracy\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # Classification report\n",
    "    print(classification_report(y_test, y_pred,target_names=subdomains))\n",
    "    \n",
    "    # Confusion Matrix Metrics\n",
    "    for i in range(len(subdomains)):\n",
    "        cmatrix = confusion_matrix(y_test.iloc[:, i], y_pred[:, i])\n",
    "        classes = [f'{subdomains[i].rstrip(\" Games\")}', f'Not {subdomains[i].rstrip(\" Games\")}']\n",
    "\n",
    "        TN = cmatrix[0][0]\n",
    "        FP = cmatrix[0][1]\n",
    "        FN = cmatrix[1][0]\n",
    "        TP = cmatrix[1][1]\n",
    "\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "\n",
    "        precision = TP/(TP+FP)\n",
    "        neg_pred = TN/(TN+FN)\n",
    "\n",
    "        accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "        print(f'Metrics for {subdomains[i]} Confusion Matrix',\n",
    "              f'\\n\\tSensitivity: {sensitivity:0.2f}',\n",
    "              f'\\n\\tSpecificity: {specificity:0.2f}',\n",
    "              f'\\n\\tPrecision: {precision:0.2f}',\n",
    "              f'\\n\\tNegative Predictive Value: {neg_pred:0.2f}',\n",
    "              f'\\n\\tAccuracy: {accuracy:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe752cf2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## confusion matrix stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef736c16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Abstract Games Confusion Matrix \n",
      "\tSensitivity: 0.56 \n",
      "\tSpecificity: 0.97 \n",
      "\tPrecision: 0.47 \n",
      "\tNegative Predictive Value: 0.98 \n",
      "\tAccuracy: 0.96\n",
      "Metrics for Children's Games Confusion Matrix \n",
      "\tSensitivity: 0.14 \n",
      "\tSpecificity: 0.99 \n",
      "\tPrecision: 0.17 \n",
      "\tNegative Predictive Value: 0.98 \n",
      "\tAccuracy: 0.97\n",
      "Metrics for Customizable Games Confusion Matrix \n",
      "\tSensitivity: 0.35 \n",
      "\tSpecificity: 0.99 \n",
      "\tPrecision: 0.55 \n",
      "\tNegative Predictive Value: 0.97 \n",
      "\tAccuracy: 0.96\n",
      "Metrics for Family Games Confusion Matrix \n",
      "\tSensitivity: 0.58 \n",
      "\tSpecificity: 0.89 \n",
      "\tPrecision: 0.72 \n",
      "\tNegative Predictive Value: 0.82 \n",
      "\tAccuracy: 0.79\n",
      "Metrics for Party Games Confusion Matrix \n",
      "\tSensitivity: 0.60 \n",
      "\tSpecificity: 0.98 \n",
      "\tPrecision: 0.75 \n",
      "\tNegative Predictive Value: 0.97 \n",
      "\tAccuracy: 0.95\n",
      "Metrics for Strategy Games Confusion Matrix \n",
      "\tSensitivity: 0.80 \n",
      "\tSpecificity: 0.81 \n",
      "\tPrecision: 0.77 \n",
      "\tNegative Predictive Value: 0.83 \n",
      "\tAccuracy: 0.80\n",
      "Metrics for Thematic Games Confusion Matrix \n",
      "\tSensitivity: 0.67 \n",
      "\tSpecificity: 0.97 \n",
      "\tPrecision: 0.85 \n",
      "\tNegative Predictive Value: 0.92 \n",
      "\tAccuracy: 0.91\n",
      "Metrics for Wargames Confusion Matrix \n",
      "\tSensitivity: 0.71 \n",
      "\tSpecificity: 0.98 \n",
      "\tPrecision: 0.82 \n",
      "\tNegative Predictive Value: 0.97 \n",
      "\tAccuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(subdomains)):\n",
    "#     cmatrix = confusion_matrix(y_test.iloc[:, i], y_pred[:, i])\n",
    "#     classes = [f'{subdomains[i].rstrip(\" Games\")}', f'Not {subdomains[i].rstrip(\" Games\")}']\n",
    "    \n",
    "#     TN = cmatrix[0][0]\n",
    "#     FP = cmatrix[0][1]\n",
    "#     FN = cmatrix[1][0]\n",
    "#     TP = cmatrix[1][1]\n",
    "    \n",
    "#     sensitivity = TP/(TP+FN)\n",
    "#     specificity = TN/(TN+FP)\n",
    "    \n",
    "#     precision = TP/(TP+FP)\n",
    "#     neg_pred = TN/(TN+FN)\n",
    "    \n",
    "#     accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    \n",
    "#     print(f'Metrics for {subdomains[i]} Confusion Matrix',\n",
    "#           f'\\n\\tSensitivity: {sensitivity:0.2f}',\n",
    "#           f'\\n\\tSpecificity: {specificity:0.2f}',\n",
    "#           f'\\n\\tPrecision: {precision:0.2f}',\n",
    "#           f'\\n\\tNegative Predictive Value: {neg_pred:0.2f}',\n",
    "#           f'\\n\\tAccuracy: {accuracy:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e97cb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fffe7ed7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m8\u001B[39m))\n\u001B[0;32m      3\u001B[0m y_score \u001B[38;5;241m=\u001B[39m multi_clf\u001B[38;5;241m.\u001B[39mpredict_proba(X_test)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# For each subdomain\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "y_score = multi_clf.predict_proba(X_test)\n",
    "\n",
    "# For each subdomain\n",
    "for i in range(len(subdomains)):\n",
    "    precision, recall, _ = precision_recall_curve(y_test.iloc[:, i], y_score[i][:, 1])\n",
    "    average_precision = average_precision_score(y_test.iloc[:, i], y_score[i][:, 1])\n",
    "\n",
    "    plt.plot(recall, precision, lw=2, label='Precision-Recall curve of class {0} (area = {1:0.2f})'\n",
    "                                           ''.format(subdomains[i], average_precision))\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves of 2017 Classifier')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(f'figures/2017/Precision Recall Curves 2017.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651e461",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(subdomains)):\n",
    "    matrix = confusion_matrix(y_test.iloc[:, i], y_pred[:, i])\n",
    "    classes = [f'{subdomains[i].rstrip(' Games')}', f'Not {subdomains[i].rstrip(' Games')}']\n",
    "    plt.matshow(matrix)\n",
    "    plt.title(f'2017 Confusion Matrix of {subdomains[i]}')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('Ground Truth')\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.xticks(range(len(classes)), classes, rotation=45)\n",
    "    plt.yticks(range(len(classes)), classes)\n",
    "    \n",
    "    for j in range(len(classes)):\n",
    "        for k in range(len(classes)):\n",
    "            plt.text(k, j, matrix[j, k], ha='center', va='center')\n",
    "    plt.savefig(f'figures/2017/confusion_matrix/{subdomains[i]} Confusion Matrix_2017.pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4121ce80",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(15, 10))\n",
    "fig.suptitle('Confusion Matrices of 2017')\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    matrix = confusion_matrix(y_test.iloc[:, i], y_pred[:, i])\n",
    "    classes = [f'{subdomains[i]}', f'Not {subdomains[i]}']\n",
    "    cax = ax.matshow(matrix, cmap=plt.cm.Blues)\n",
    "    fig.colorbar(cax, ax=ax)\n",
    "    ax.set_title(f'{subdomains[i]}')\n",
    "    ax.set_ylabel('Ground Truth')\n",
    "    ax.set_xlabel('Prediction')\n",
    "    ax.set_xticks(range(len(classes)))\n",
    "    ax.set_yticks(range(len(classes)))\n",
    "    ax.set_xticklabels(classes, rotation=45)\n",
    "    ax.set_yticklabels(classes)\n",
    "    \n",
    "    for j in range(len(classes)):\n",
    "        for k in range(len(classes)):\n",
    "            ax.text(k, j, matrix[j, k], ha='center', va='center')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96]) \n",
    "plt.savefig('figures/2017/Confusion Matrices_2017.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d9245",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to hold the feature importances\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = X.columns\n",
    "\n",
    "# For each classifier in the multi output classifier\n",
    "for i, classifier in enumerate(multi_clf.estimators_):\n",
    "    # Get the feature importances\n",
    "    importances = classifier.feature_importances_\n",
    "    \n",
    "    # Add these importances to the DataFrame\n",
    "    feature_importances[f'importance_{subdomains[i]}'] = importances\n",
    "\n",
    "# Print the DataFrame\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dccdf9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# For each class\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(len(subdomains)):\n",
    "    # Initialize figure for this class\n",
    "\n",
    "    plt.plot(recall[i], precision[i], label='Precision-Recall curve of class {0} (area = {1:0.2f})'\n",
    "                                           ''.format(subdomains[i], average_precision[i]))\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall curve for {subdomains[i]}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f268c67",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(15, 10))\n",
    "fig.suptitle('Confusion Matrices of 2017')\n",
    "\n",
    "# Initialize the aggregate confusion matrix\n",
    "aggregate_matrix = np.zeros((2, 2))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    matrix = confusion_matrix(y_test.iloc[:, i], y_pred[:, i])\n",
    "    \n",
    "    # Add the current matrix to the aggregate matrix\n",
    "    aggregate_matrix += matrix\n",
    "\n",
    "    classes = [f'{subdomains[i]}', f'Not {subdomains[i]}']\n",
    "    cax = ax.matshow(matrix, cmap=plt.cm.Blues)\n",
    "    fig.colorbar(cax, ax=ax)\n",
    "    ax.set_title(f'{subdomains[i]}')\n",
    "    ax.set_ylabel('Ground Truth')\n",
    "    ax.set_xlabel('Prediction')\n",
    "    ax.set_xticks(range(len(classes)))\n",
    "    ax.set_yticks(range(len(classes)))\n",
    "    ax.set_xticklabels(classes, rotation=45)\n",
    "    ax.set_yticklabels(classes)\n",
    "    \n",
    "    for j in range(len(classes)):\n",
    "        for k in range(len(classes)):\n",
    "            ax.text(k, j, matrix[j, k], ha='center', va='center')\n",
    "\n",
    "# Print or plot the aggregate confusion matrix as required\n",
    "print(aggregate_matrix)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96]) \n",
    "plt.savefig('figures/2017/Confusion Matrices_2017.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064a94f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}